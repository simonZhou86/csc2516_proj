Traceback (most recent call last):
  File "main.py", line 215, in <module>
    train(args)
  File "main.py", line 151, in train
    train_epoch(args, model, train_loader, optimizer, scheduler, device, epoch)
  File "main.py", line 38, in train_epoch
    pred_seg, pred_recon = model(img)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 150, in forward
    return self.module(*inputs, **kwargs)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/xudongliu/work_flow/csc2516_proj/network.py", line 576, in forward
    seg_map = self.segmentor(lat_feat, concat_feats)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/xudongliu/work_flow/csc2516_proj/network.py", line 466, in forward
    x = self.up5(lat_feat)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/xudongliu/work_flow/csc2516_proj/network.py", line 167, in forward
    x = self.up(x)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/Users/xudongliu/opt/anaconda3/envs/vision/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [512, 1024, 3, 3], expected input[1, 2, 64, 2048] to have 1024 channels, but got 2 channels instead